{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zoM6-2bR2Mt",
    "outputId": "60329102-755f-424e-8c0e-8609cb2edc2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.1.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle --upgrade\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-rWdBdvXOg3r"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PKkS4riTW3W",
    "outputId": "c838d3a0-4dfe-4591-f7ad-42cf4540264f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/thienkhonghoc/affectnet\n",
      "License(s): unknown\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d thienkhonghoc/affectnet -p /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QqGmBUfoOlSx"
   },
   "outputs": [],
   "source": [
    "!unzip -q /content/affectnet.zip -d /content/affectnet > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ko0mXTVrzPiZ",
    "outputId": "6bb6d04f-e6e7-4e98-c3e1-cc7788d5a73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.29.3)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision timm matplotlib tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gVKyAMHxkHXB",
    "outputId": "b70891f5-114b-4f00-bfd2-fca3f5b2e96e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded! Resuming training from Epoch 11.\n",
      "\n",
      "Continuing Fine-tuning from Epoch 11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1892beaaac7>:101: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "<ipython-input-13-e1892beaaac7>:125: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Processed 50 batches...\n",
      "Epoch 11: Processed 100 batches...\n",
      "Epoch 11: Processed 150 batches...\n",
      "Epoch 11: Processed 200 batches...\n",
      "Epoch 11: Processed 250 batches...\n",
      "Epoch 11: Processed 300 batches...\n",
      "Epoch 11: Processed 350 batches...\n",
      "Epoch 11: Processed 400 batches...\n",
      "Epoch 11: Processed 450 batches...\n",
      "Epoch 11: Processed 500 batches...\n",
      "Epoch 11: Processed 550 batches...\n",
      "Epoch 11: Processed 600 batches...\n",
      "Epoch 11: Processed 650 batches...\n",
      "Epoch 11: Processed 700 batches...\n",
      "Epoch 11: Processed 750 batches...\n",
      "Epoch 11: Processed 800 batches...\n",
      "Epoch 11: Processed 850 batches...\n",
      "Epoch 11: Processed 900 batches...\n",
      "Epoch 11: Processed 950 batches...\n",
      "Epoch 11: Processed 1000 batches...\n",
      "Epoch 11: Processed 1050 batches...\n",
      "Epoch 11: Processed 1100 batches...\n",
      "Epoch 11: Processed 1150 batches...\n",
      "Epoch 11: Processed 1200 batches...\n",
      "Epoch 11: Processed 1250 batches...\n",
      "Epoch 11: Processed 1300 batches...\n",
      "Epoch 11: Processed 1350 batches...\n",
      "Epoch 11: Processed 1400 batches...\n",
      "Epoch 11: Processed 1450 batches...\n",
      "Epoch 11: Processed 1500 batches...\n",
      "Epoch 11: Processed 1550 batches...\n",
      "Epoch 11: Processed 1600 batches...\n",
      "Epoch 11: Processed 1650 batches...\n",
      "Epoch 11: Processed 1700 batches...\n",
      "Epoch 11: Processed 1750 batches...\n",
      "Epoch 11: Processed 1800 batches...\n",
      "Epoch 11: Processed 1850 batches...\n",
      "Epoch 11: Processed 1900 batches...\n",
      "Epoch 11: Processed 1950 batches...\n",
      "Epoch 11: Processed 2000 batches...\n",
      "Epoch 11: Processed 2050 batches...\n",
      "Epoch 11: Processed 2100 batches...\n",
      "Epoch 11: Processed 2150 batches...\n",
      "Epoch 11: Processed 2200 batches...\n",
      "Epoch 11: Processed 2250 batches...\n",
      "Epoch 11: Processed 2300 batches...\n",
      "Epoch [11/25], Loss: 3052.2423, Train Acc: 61.48%, Val Acc: 58.25%\n",
      "Epoch 12: Processed 50 batches...\n",
      "Epoch 12: Processed 100 batches...\n",
      "Epoch 12: Processed 150 batches...\n",
      "Epoch 12: Processed 200 batches...\n",
      "Epoch 12: Processed 250 batches...\n",
      "Epoch 12: Processed 300 batches...\n",
      "Epoch 12: Processed 350 batches...\n",
      "Epoch 12: Processed 400 batches...\n",
      "Epoch 12: Processed 450 batches...\n",
      "Epoch 12: Processed 500 batches...\n",
      "Epoch 12: Processed 550 batches...\n",
      "Epoch 12: Processed 600 batches...\n",
      "Epoch 12: Processed 650 batches...\n",
      "Epoch 12: Processed 700 batches...\n",
      "Epoch 12: Processed 750 batches...\n",
      "Epoch 12: Processed 800 batches...\n",
      "Epoch 12: Processed 850 batches...\n",
      "Epoch 12: Processed 900 batches...\n",
      "Epoch 12: Processed 950 batches...\n",
      "Epoch 12: Processed 1000 batches...\n",
      "Epoch 12: Processed 1050 batches...\n",
      "Epoch 12: Processed 1100 batches...\n",
      "Epoch 12: Processed 1150 batches...\n",
      "Epoch 12: Processed 1200 batches...\n",
      "Epoch 12: Processed 1250 batches...\n",
      "Epoch 12: Processed 1300 batches...\n",
      "Epoch 12: Processed 1350 batches...\n",
      "Epoch 12: Processed 1400 batches...\n",
      "Epoch 12: Processed 1450 batches...\n",
      "Epoch 12: Processed 1500 batches...\n",
      "Epoch 12: Processed 1550 batches...\n",
      "Epoch 12: Processed 1600 batches...\n",
      "Epoch 12: Processed 1650 batches...\n",
      "Epoch 12: Processed 1700 batches...\n",
      "Epoch 12: Processed 1750 batches...\n",
      "Epoch 12: Processed 1800 batches...\n",
      "Epoch 12: Processed 1850 batches...\n",
      "Epoch 12: Processed 1900 batches...\n",
      "Epoch 12: Processed 1950 batches...\n",
      "Epoch 12: Processed 2000 batches...\n",
      "Epoch 12: Processed 2050 batches...\n",
      "Epoch 12: Processed 2100 batches...\n",
      "Epoch 12: Processed 2150 batches...\n",
      "Epoch 12: Processed 2200 batches...\n",
      "Epoch 12: Processed 2250 batches...\n",
      "Epoch 12: Processed 2300 batches...\n",
      "Epoch [12/25], Loss: 2827.8074, Train Acc: 65.69%, Val Acc: 60.00%\n",
      "Epoch 13: Processed 50 batches...\n",
      "Epoch 13: Processed 100 batches...\n",
      "Epoch 13: Processed 150 batches...\n",
      "Epoch 13: Processed 200 batches...\n",
      "Epoch 13: Processed 250 batches...\n",
      "Epoch 13: Processed 300 batches...\n",
      "Epoch 13: Processed 350 batches...\n",
      "Epoch 13: Processed 400 batches...\n",
      "Epoch 13: Processed 450 batches...\n",
      "Epoch 13: Processed 500 batches...\n",
      "Epoch 13: Processed 550 batches...\n",
      "Epoch 13: Processed 600 batches...\n",
      "Epoch 13: Processed 650 batches...\n",
      "Epoch 13: Processed 700 batches...\n",
      "Epoch 13: Processed 750 batches...\n",
      "Epoch 13: Processed 800 batches...\n",
      "Epoch 13: Processed 850 batches...\n",
      "Epoch 13: Processed 900 batches...\n",
      "Epoch 13: Processed 950 batches...\n",
      "Epoch 13: Processed 1000 batches...\n",
      "Epoch 13: Processed 1050 batches...\n",
      "Epoch 13: Processed 1100 batches...\n",
      "Epoch 13: Processed 1150 batches...\n",
      "Epoch 13: Processed 1200 batches...\n",
      "Epoch 13: Processed 1250 batches...\n",
      "Epoch 13: Processed 1300 batches...\n",
      "Epoch 13: Processed 1350 batches...\n",
      "Epoch 13: Processed 1400 batches...\n",
      "Epoch 13: Processed 1450 batches...\n",
      "Epoch 13: Processed 1500 batches...\n",
      "Epoch 13: Processed 1550 batches...\n",
      "Epoch 13: Processed 1600 batches...\n",
      "Epoch 13: Processed 1650 batches...\n",
      "Epoch 13: Processed 1700 batches...\n",
      "Epoch 13: Processed 1750 batches...\n",
      "Epoch 13: Processed 1800 batches...\n",
      "Epoch 13: Processed 1850 batches...\n",
      "Epoch 13: Processed 1900 batches...\n",
      "Epoch 13: Processed 1950 batches...\n",
      "Epoch 13: Processed 2000 batches...\n",
      "Epoch 13: Processed 2050 batches...\n",
      "Epoch 13: Processed 2100 batches...\n",
      "Epoch 13: Processed 2150 batches...\n",
      "Epoch 13: Processed 2200 batches...\n",
      "Epoch 13: Processed 2250 batches...\n",
      "Epoch 13: Processed 2300 batches...\n",
      "Epoch [13/25], Loss: 2741.3062, Train Acc: 67.50%, Val Acc: 58.12%\n",
      "Epoch 14: Processed 50 batches...\n",
      "Epoch 14: Processed 100 batches...\n",
      "Epoch 14: Processed 150 batches...\n",
      "Epoch 14: Processed 200 batches...\n",
      "Epoch 14: Processed 250 batches...\n",
      "Epoch 14: Processed 300 batches...\n",
      "Epoch 14: Processed 350 batches...\n",
      "Epoch 14: Processed 400 batches...\n",
      "Epoch 14: Processed 450 batches...\n",
      "Epoch 14: Processed 500 batches...\n",
      "Epoch 14: Processed 550 batches...\n",
      "Epoch 14: Processed 600 batches...\n",
      "Epoch 14: Processed 650 batches...\n",
      "Epoch 14: Processed 700 batches...\n",
      "Epoch 14: Processed 750 batches...\n",
      "Epoch 14: Processed 800 batches...\n",
      "Epoch 14: Processed 850 batches...\n",
      "Epoch 14: Processed 900 batches...\n",
      "Epoch 14: Processed 950 batches...\n",
      "Epoch 14: Processed 1000 batches...\n",
      "Epoch 14: Processed 1050 batches...\n",
      "Epoch 14: Processed 1100 batches...\n",
      "Epoch 14: Processed 1150 batches...\n",
      "Epoch 14: Processed 1200 batches...\n",
      "Epoch 14: Processed 1250 batches...\n",
      "Epoch 14: Processed 1300 batches...\n",
      "Epoch 14: Processed 1350 batches...\n",
      "Epoch 14: Processed 1400 batches...\n",
      "Epoch 14: Processed 1450 batches...\n",
      "Epoch 14: Processed 1500 batches...\n",
      "Epoch 14: Processed 1550 batches...\n",
      "Epoch 14: Processed 1600 batches...\n",
      "Epoch 14: Processed 1650 batches...\n",
      "Epoch 14: Processed 1700 batches...\n",
      "Epoch 14: Processed 1750 batches...\n",
      "Epoch 14: Processed 1800 batches...\n",
      "Epoch 14: Processed 1850 batches...\n",
      "Epoch 14: Processed 1900 batches...\n",
      "Epoch 14: Processed 1950 batches...\n",
      "Epoch 14: Processed 2000 batches...\n",
      "Epoch 14: Processed 2050 batches...\n",
      "Epoch 14: Processed 2100 batches...\n",
      "Epoch 14: Processed 2150 batches...\n",
      "Epoch 14: Processed 2200 batches...\n",
      "Epoch 14: Processed 2250 batches...\n",
      "Epoch 14: Processed 2300 batches...\n",
      "Epoch [14/25], Loss: 2656.7292, Train Acc: 69.32%, Val Acc: 59.25%\n",
      "Epoch 15: Processed 50 batches...\n",
      "Epoch 15: Processed 100 batches...\n",
      "Epoch 15: Processed 150 batches...\n",
      "Epoch 15: Processed 200 batches...\n",
      "Epoch 15: Processed 250 batches...\n",
      "Epoch 15: Processed 300 batches...\n",
      "Epoch 15: Processed 350 batches...\n",
      "Epoch 15: Processed 400 batches...\n",
      "Epoch 15: Processed 450 batches...\n",
      "Epoch 15: Processed 500 batches...\n",
      "Epoch 15: Processed 550 batches...\n",
      "Epoch 15: Processed 600 batches...\n",
      "Epoch 15: Processed 650 batches...\n",
      "Epoch 15: Processed 700 batches...\n",
      "Epoch 15: Processed 750 batches...\n",
      "Epoch 15: Processed 800 batches...\n",
      "Epoch 15: Processed 850 batches...\n",
      "Epoch 15: Processed 900 batches...\n",
      "Epoch 15: Processed 950 batches...\n",
      "Epoch 15: Processed 1000 batches...\n",
      "Epoch 15: Processed 1050 batches...\n",
      "Epoch 15: Processed 1100 batches...\n",
      "Epoch 15: Processed 1150 batches...\n",
      "Epoch 15: Processed 1200 batches...\n",
      "Epoch 15: Processed 1250 batches...\n",
      "Epoch 15: Processed 1300 batches...\n",
      "Epoch 15: Processed 1350 batches...\n",
      "Epoch 15: Processed 1400 batches...\n",
      "Epoch 15: Processed 1450 batches...\n",
      "Epoch 15: Processed 1500 batches...\n",
      "Epoch 15: Processed 1550 batches...\n",
      "Epoch 15: Processed 1600 batches...\n",
      "Epoch 15: Processed 1650 batches...\n",
      "Epoch 15: Processed 1700 batches...\n",
      "Epoch 15: Processed 1750 batches...\n",
      "Epoch 15: Processed 1800 batches...\n",
      "Epoch 15: Processed 1850 batches...\n",
      "Epoch 15: Processed 1900 batches...\n",
      "Epoch 15: Processed 1950 batches...\n",
      "Epoch 15: Processed 2000 batches...\n",
      "Epoch 15: Processed 2050 batches...\n",
      "Epoch 15: Processed 2100 batches...\n",
      "Epoch 15: Processed 2150 batches...\n",
      "Epoch 15: Processed 2200 batches...\n",
      "Epoch 15: Processed 2250 batches...\n",
      "Epoch 15: Processed 2300 batches...\n",
      "Epoch [15/25], Loss: 2578.4818, Train Acc: 71.25%, Val Acc: 58.12%\n",
      "Model saved: affectnet_convnext_large_epoch15.pt\n",
      "Epoch 16: Processed 50 batches...\n",
      "Epoch 16: Processed 100 batches...\n",
      "Epoch 16: Processed 150 batches...\n",
      "Epoch 16: Processed 200 batches...\n",
      "Epoch 16: Processed 250 batches...\n",
      "Epoch 16: Processed 300 batches...\n",
      "Epoch 16: Processed 350 batches...\n",
      "Epoch 16: Processed 400 batches...\n",
      "Epoch 16: Processed 450 batches...\n",
      "Epoch 16: Processed 500 batches...\n",
      "Epoch 16: Processed 550 batches...\n",
      "Epoch 16: Processed 600 batches...\n",
      "Epoch 16: Processed 650 batches...\n",
      "Epoch 16: Processed 700 batches...\n",
      "Epoch 16: Processed 750 batches...\n",
      "Epoch 16: Processed 800 batches...\n",
      "Epoch 16: Processed 850 batches...\n",
      "Epoch 16: Processed 900 batches...\n",
      "Epoch 16: Processed 950 batches...\n",
      "Epoch 16: Processed 1000 batches...\n",
      "Epoch 16: Processed 1050 batches...\n",
      "Epoch 16: Processed 1100 batches...\n",
      "Epoch 16: Processed 1150 batches...\n",
      "Epoch 16: Processed 1200 batches...\n",
      "Epoch 16: Processed 1250 batches...\n",
      "Epoch 16: Processed 1300 batches...\n",
      "Epoch 16: Processed 1350 batches...\n",
      "Epoch 16: Processed 1400 batches...\n",
      "Epoch 16: Processed 1450 batches...\n",
      "Epoch 16: Processed 1500 batches...\n",
      "Epoch 16: Processed 1550 batches...\n",
      "Epoch 16: Processed 1600 batches...\n",
      "Epoch 16: Processed 1650 batches...\n",
      "Epoch 16: Processed 1700 batches...\n",
      "Epoch 16: Processed 1750 batches...\n",
      "Epoch 16: Processed 1800 batches...\n",
      "Epoch 16: Processed 1850 batches...\n",
      "Epoch 16: Processed 1900 batches...\n",
      "Epoch 16: Processed 1950 batches...\n",
      "Epoch 16: Processed 2000 batches...\n",
      "Epoch 16: Processed 2050 batches...\n",
      "Epoch 16: Processed 2100 batches...\n",
      "Epoch 16: Processed 2150 batches...\n",
      "Epoch 16: Processed 2200 batches...\n",
      "Epoch 16: Processed 2250 batches...\n",
      "Epoch 16: Processed 2300 batches...\n",
      "Epoch [16/25], Loss: 2498.6273, Train Acc: 72.98%, Val Acc: 60.62%\n",
      "Epoch 17: Processed 50 batches...\n",
      "Epoch 17: Processed 100 batches...\n",
      "Epoch 17: Processed 150 batches...\n",
      "Epoch 17: Processed 200 batches...\n",
      "Epoch 17: Processed 250 batches...\n",
      "Epoch 17: Processed 300 batches...\n",
      "Epoch 17: Processed 350 batches...\n",
      "Epoch 17: Processed 400 batches...\n",
      "Epoch 17: Processed 450 batches...\n",
      "Epoch 17: Processed 500 batches...\n",
      "Epoch 17: Processed 550 batches...\n",
      "Epoch 17: Processed 600 batches...\n",
      "Epoch 17: Processed 650 batches...\n",
      "Epoch 17: Processed 700 batches...\n",
      "Epoch 17: Processed 750 batches...\n",
      "Epoch 17: Processed 800 batches...\n",
      "Epoch 17: Processed 850 batches...\n",
      "Epoch 17: Processed 900 batches...\n",
      "Epoch 17: Processed 950 batches...\n",
      "Epoch 17: Processed 1000 batches...\n",
      "Epoch 17: Processed 1050 batches...\n",
      "Epoch 17: Processed 1100 batches...\n",
      "Epoch 17: Processed 1150 batches...\n",
      "Epoch 17: Processed 1200 batches...\n",
      "Epoch 17: Processed 1250 batches...\n",
      "Epoch 17: Processed 1300 batches...\n",
      "Epoch 17: Processed 1350 batches...\n",
      "Epoch 17: Processed 1400 batches...\n",
      "Epoch 17: Processed 1450 batches...\n",
      "Epoch 17: Processed 1500 batches...\n",
      "Epoch 17: Processed 1550 batches...\n",
      "Epoch 17: Processed 1600 batches...\n",
      "Epoch 17: Processed 1650 batches...\n",
      "Epoch 17: Processed 1700 batches...\n",
      "Epoch 17: Processed 1750 batches...\n",
      "Epoch 17: Processed 1800 batches...\n",
      "Epoch 17: Processed 1850 batches...\n",
      "Epoch 17: Processed 1900 batches...\n",
      "Epoch 17: Processed 1950 batches...\n",
      "Epoch 17: Processed 2000 batches...\n",
      "Epoch 17: Processed 2050 batches...\n",
      "Epoch 17: Processed 2100 batches...\n",
      "Epoch 17: Processed 2150 batches...\n",
      "Epoch 17: Processed 2200 batches...\n",
      "Epoch 17: Processed 2250 batches...\n",
      "Epoch 17: Processed 2300 batches...\n",
      "Epoch [17/25], Loss: 2419.7996, Train Acc: 74.43%, Val Acc: 58.00%\n",
      "Epoch 18: Processed 50 batches...\n",
      "Epoch 18: Processed 100 batches...\n",
      "Epoch 18: Processed 150 batches...\n",
      "Epoch 18: Processed 200 batches...\n",
      "Epoch 18: Processed 250 batches...\n",
      "Epoch 18: Processed 300 batches...\n",
      "Epoch 18: Processed 350 batches...\n",
      "Epoch 18: Processed 400 batches...\n",
      "Epoch 18: Processed 450 batches...\n",
      "Epoch 18: Processed 500 batches...\n",
      "Epoch 18: Processed 550 batches...\n",
      "Epoch 18: Processed 600 batches...\n",
      "Epoch 18: Processed 650 batches...\n",
      "Epoch 18: Processed 700 batches...\n",
      "Epoch 18: Processed 750 batches...\n",
      "Epoch 18: Processed 800 batches...\n",
      "Epoch 18: Processed 850 batches...\n",
      "Epoch 18: Processed 900 batches...\n",
      "Epoch 18: Processed 950 batches...\n",
      "Epoch 18: Processed 1000 batches...\n",
      "Epoch 18: Processed 1050 batches...\n",
      "Epoch 18: Processed 1100 batches...\n",
      "Epoch 18: Processed 1150 batches...\n",
      "Epoch 18: Processed 1200 batches...\n",
      "Epoch 18: Processed 1250 batches...\n",
      "Epoch 18: Processed 1300 batches...\n",
      "Epoch 18: Processed 1350 batches...\n",
      "Epoch 18: Processed 1400 batches...\n",
      "Epoch 18: Processed 1450 batches...\n",
      "Epoch 18: Processed 1500 batches...\n",
      "Epoch 18: Processed 1550 batches...\n",
      "Epoch 18: Processed 1600 batches...\n",
      "Epoch 18: Processed 1650 batches...\n",
      "Epoch 18: Processed 1700 batches...\n",
      "Epoch 18: Processed 1750 batches...\n",
      "Epoch 18: Processed 1800 batches...\n",
      "Epoch 18: Processed 1850 batches...\n",
      "Epoch 18: Processed 1900 batches...\n",
      "Epoch 18: Processed 1950 batches...\n",
      "Epoch 18: Processed 2000 batches...\n",
      "Epoch 18: Processed 2050 batches...\n",
      "Epoch 18: Processed 2100 batches...\n",
      "Epoch 18: Processed 2150 batches...\n",
      "Epoch 18: Processed 2200 batches...\n",
      "Epoch 18: Processed 2250 batches...\n",
      "Epoch 18: Processed 2300 batches...\n",
      "Epoch [18/25], Loss: 2383.8815, Train Acc: 75.20%, Val Acc: 60.25%\n",
      "Epoch 19: Processed 50 batches...\n",
      "Epoch 19: Processed 100 batches...\n",
      "Epoch 19: Processed 150 batches...\n",
      "Epoch 19: Processed 200 batches...\n",
      "Epoch 19: Processed 250 batches...\n",
      "Epoch 19: Processed 300 batches...\n",
      "Epoch 19: Processed 350 batches...\n",
      "Epoch 19: Processed 400 batches...\n",
      "Epoch 19: Processed 450 batches...\n",
      "Epoch 19: Processed 500 batches...\n",
      "Epoch 19: Processed 550 batches...\n",
      "Epoch 19: Processed 600 batches...\n",
      "Epoch 19: Processed 650 batches...\n",
      "Epoch 19: Processed 700 batches...\n",
      "Epoch 19: Processed 750 batches...\n",
      "Epoch 19: Processed 800 batches...\n",
      "Epoch 19: Processed 850 batches...\n",
      "Epoch 19: Processed 900 batches...\n",
      "Epoch 19: Processed 950 batches...\n",
      "Epoch 19: Processed 1000 batches...\n",
      "Epoch 19: Processed 1050 batches...\n",
      "Epoch 19: Processed 1100 batches...\n",
      "Epoch 19: Processed 1150 batches...\n",
      "Epoch 19: Processed 1200 batches...\n",
      "Epoch 19: Processed 1250 batches...\n",
      "Epoch 19: Processed 1300 batches...\n",
      "Epoch 19: Processed 1350 batches...\n",
      "Epoch 19: Processed 1400 batches...\n",
      "Epoch 19: Processed 1450 batches...\n",
      "Epoch 19: Processed 1500 batches...\n",
      "Epoch 19: Processed 1550 batches...\n",
      "Epoch 19: Processed 1600 batches...\n",
      "Epoch 19: Processed 1650 batches...\n",
      "Epoch 19: Processed 1700 batches...\n",
      "Epoch 19: Processed 1750 batches...\n",
      "Epoch 19: Processed 1800 batches...\n",
      "Epoch 19: Processed 1850 batches...\n",
      "Epoch 19: Processed 1900 batches...\n",
      "Epoch 19: Processed 1950 batches...\n",
      "Epoch 19: Processed 2000 batches...\n",
      "Epoch 19: Processed 2050 batches...\n",
      "Epoch 19: Processed 2100 batches...\n",
      "Epoch 19: Processed 2150 batches...\n",
      "Epoch 19: Processed 2200 batches...\n",
      "Epoch 19: Processed 2250 batches...\n",
      "Epoch 19: Processed 2300 batches...\n",
      "Epoch [19/25], Loss: 2358.1169, Train Acc: 75.80%, Val Acc: 58.12%\n",
      "Epoch 20: Processed 50 batches...\n",
      "Epoch 20: Processed 100 batches...\n",
      "Epoch 20: Processed 150 batches...\n",
      "Epoch 20: Processed 200 batches...\n",
      "Epoch 20: Processed 250 batches...\n",
      "Epoch 20: Processed 300 batches...\n",
      "Epoch 20: Processed 350 batches...\n",
      "Epoch 20: Processed 400 batches...\n",
      "Epoch 20: Processed 450 batches...\n",
      "Epoch 20: Processed 500 batches...\n",
      "Epoch 20: Processed 550 batches...\n",
      "Epoch 20: Processed 600 batches...\n",
      "Epoch 20: Processed 650 batches...\n",
      "Epoch 20: Processed 700 batches...\n",
      "Epoch 20: Processed 750 batches...\n",
      "Epoch 20: Processed 800 batches...\n",
      "Epoch 20: Processed 850 batches...\n",
      "Epoch 20: Processed 900 batches...\n",
      "Epoch 20: Processed 950 batches...\n",
      "Epoch 20: Processed 1000 batches...\n",
      "Epoch 20: Processed 1050 batches...\n",
      "Epoch 20: Processed 1100 batches...\n",
      "Epoch 20: Processed 1150 batches...\n",
      "Epoch 20: Processed 1200 batches...\n",
      "Epoch 20: Processed 1250 batches...\n",
      "Epoch 20: Processed 1300 batches...\n",
      "Epoch 20: Processed 1350 batches...\n",
      "Epoch 20: Processed 1400 batches...\n",
      "Epoch 20: Processed 1450 batches...\n",
      "Epoch 20: Processed 1500 batches...\n",
      "Epoch 20: Processed 1550 batches...\n",
      "Epoch 20: Processed 1600 batches...\n",
      "Epoch 20: Processed 1650 batches...\n",
      "Epoch 20: Processed 1700 batches...\n",
      "Epoch 20: Processed 1750 batches...\n",
      "Epoch 20: Processed 1800 batches...\n",
      "Epoch 20: Processed 1850 batches...\n",
      "Epoch 20: Processed 1900 batches...\n",
      "Epoch 20: Processed 1950 batches...\n",
      "Epoch 20: Processed 2000 batches...\n",
      "Epoch 20: Processed 2050 batches...\n",
      "Epoch 20: Processed 2100 batches...\n",
      "Epoch 20: Processed 2150 batches...\n",
      "Epoch 20: Processed 2200 batches...\n",
      "Epoch 20: Processed 2250 batches...\n",
      "Epoch 20: Processed 2300 batches...\n",
      "Epoch [20/25], Loss: 2339.9390, Train Acc: 76.20%, Val Acc: 59.00%\n",
      "Model saved: affectnet_convnext_large_epoch20.pt\n",
      "Epoch 21: Processed 50 batches...\n",
      "Epoch 21: Processed 100 batches...\n",
      "Epoch 21: Processed 150 batches...\n",
      "Epoch 21: Processed 200 batches...\n",
      "Epoch 21: Processed 250 batches...\n",
      "Epoch 21: Processed 300 batches...\n",
      "Epoch 21: Processed 350 batches...\n",
      "Epoch 21: Processed 400 batches...\n",
      "Epoch 21: Processed 450 batches...\n",
      "Epoch 21: Processed 500 batches...\n",
      "Epoch 21: Processed 550 batches...\n",
      "Epoch 21: Processed 600 batches...\n",
      "Epoch 21: Processed 650 batches...\n",
      "Epoch 21: Processed 700 batches...\n",
      "Epoch 21: Processed 750 batches...\n",
      "Epoch 21: Processed 800 batches...\n",
      "Epoch 21: Processed 850 batches...\n",
      "Epoch 21: Processed 900 batches...\n",
      "Epoch 21: Processed 950 batches...\n",
      "Epoch 21: Processed 1000 batches...\n",
      "Epoch 21: Processed 1050 batches...\n",
      "Epoch 21: Processed 1100 batches...\n",
      "Epoch 21: Processed 1150 batches...\n",
      "Epoch 21: Processed 1200 batches...\n",
      "Epoch 21: Processed 1250 batches...\n",
      "Epoch 21: Processed 1300 batches...\n",
      "Epoch 21: Processed 1350 batches...\n",
      "Epoch 21: Processed 1400 batches...\n",
      "Epoch 21: Processed 1450 batches...\n",
      "Epoch 21: Processed 1500 batches...\n",
      "Epoch 21: Processed 1550 batches...\n",
      "Epoch 21: Processed 1600 batches...\n",
      "Epoch 21: Processed 1650 batches...\n",
      "Epoch 21: Processed 1700 batches...\n",
      "Epoch 21: Processed 1750 batches...\n",
      "Epoch 21: Processed 1800 batches...\n",
      "Epoch 21: Processed 1850 batches...\n",
      "Epoch 21: Processed 1900 batches...\n",
      "Epoch 21: Processed 1950 batches...\n",
      "Epoch 21: Processed 2000 batches...\n",
      "Epoch 21: Processed 2050 batches...\n",
      "Epoch 21: Processed 2100 batches...\n",
      "Epoch 21: Processed 2150 batches...\n",
      "Epoch 21: Processed 2200 batches...\n",
      "Epoch 21: Processed 2250 batches...\n",
      "Epoch 21: Processed 2300 batches...\n",
      "Epoch [21/25], Loss: 2322.2408, Train Acc: 76.62%, Val Acc: 57.12%\n",
      "Epoch 22: Processed 50 batches...\n",
      "Epoch 22: Processed 100 batches...\n",
      "Epoch 22: Processed 150 batches...\n",
      "Epoch 22: Processed 200 batches...\n",
      "Epoch 22: Processed 250 batches...\n",
      "Epoch 22: Processed 300 batches...\n",
      "Epoch 22: Processed 350 batches...\n",
      "Epoch 22: Processed 400 batches...\n",
      "Epoch 22: Processed 450 batches...\n",
      "Epoch 22: Processed 500 batches...\n",
      "Epoch 22: Processed 550 batches...\n",
      "Epoch 22: Processed 600 batches...\n",
      "Epoch 22: Processed 650 batches...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e1892beaaac7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to Filter Corrupt Images\n",
    "def filter_corrupt_images(dataset):\n",
    "    valid_samples = []\n",
    "    for path, label in dataset.samples:\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")  # Ensure proper format\n",
    "            valid_samples.append((path, label))\n",
    "        except Exception as e:\n",
    "            print(f\"Corrupt image removed: {path} - {e}\")\n",
    "    dataset.samples = valid_samples\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\") if isinstance(img, Image.Image) else img),  # Ensure RGB format\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.RandomErasing(p=0.3),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "train_data_path = \"/content/affectnet/AffectNet/train\"\n",
    "val_data_path = \"/content/affectnet/AffectNet/val\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_data_path, transform=transform)\n",
    "\n",
    "# Filter Out Corrupt Images Before Training\n",
    "filter_corrupt_images(train_dataset)\n",
    "filter_corrupt_images(val_dataset)\n",
    "\n",
    "# Compute Class Weights\n",
    "class_counts = Counter(train_dataset.targets)\n",
    "num_samples = sum(class_counts.values())\n",
    "weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Load Data\n",
    "batch_size = 16  # Reduced batch size to prevent OOM errors\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Load ConvNeXt-Large Model\n",
    "model = models.convnext_large(weights=models.ConvNeXt_Large_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify Classifier for 8 Classes\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.LayerNorm(model.classifier[2].in_features),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(model.classifier[2].in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(512, 8)\n",
    ")\n",
    "\n",
    "# Load Checkpoint\n",
    "checkpoint_path = \"/content/affectnet_convnext_large_epoch10.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# Remove \"_orig_mod.\" keys if necessary\n",
    "new_checkpoint = {}\n",
    "for key in checkpoint.keys():\n",
    "    new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "    new_checkpoint[new_key] = checkpoint[key]\n",
    "\n",
    "# Load State Dict\n",
    "model.load_state_dict(new_checkpoint, strict=False)\n",
    "\n",
    "print(\"Checkpoint successfully loaded! Resuming training from Epoch 11.\")\n",
    "\n",
    "# Move Model to Device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Loss, Optimizer & Scheduler\n",
    "criterion = nn.CrossEntropyLoss(weight=weights, label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-7)\n",
    "\n",
    "# Mixed Precision Training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Resume Training from 11th Epoch\n",
    "print(\"\\nContinuing Fine-tuning from Epoch 11...\\n\")\n",
    "\n",
    "for epoch in range(11, 26):\n",
    "    torch.cuda.empty_cache()  # Prevent memory fragmentation\n",
    "    model.train()\n",
    "    running_loss, correct_train, total_train = 0.0, 0, 0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    batch_count = 0  # Track processed batches\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        try:\n",
    "            if images is None or labels is None:\n",
    "                continue  # Skip NoneType images\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping corrupt batch: {e}\")\n",
    "            continue\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "        batch_count += 1\n",
    "        if batch_count % 50 == 0:  # Print every 50 batches\n",
    "            print(f\"Epoch {epoch}: Processed {batch_count} batches...\")\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    correct_val, total_val = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            try:\n",
    "                if images is None or labels is None:\n",
    "                    continue  # Skip NoneType images\n",
    "\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping corrupt batch in validation: {e}\")\n",
    "                continue\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "    print(f\"Epoch [{epoch}/25], Loss: {running_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save Model Every 5 Epochs and every 500 batches\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"affectnet_convnext_large_epoch{epoch}.pt\")\n",
    "        print(f\"Model saved: affectnet_convnext_large_epoch{epoch}.pt\")\n",
    "\n",
    "# Save Final Model\n",
    "torch.save(model.state_dict(), \"affectnet_convnext_large_final.pt\")\n",
    "print(\"\\nTraining complete! Final model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDBRHuBY3S6F",
    "outputId": "51cc70b4-f4bf-4518-81b1-b361fce0205e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded! Resuming training from Epoch 22.\n",
      "\n",
      "Continuing Fine-tuning from Epoch 22...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "<ipython-input-14-51c69459886b>:98: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "<ipython-input-14-51c69459886b>:123: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Processed 50 batches...\n",
      "Epoch 22: Processed 100 batches...\n",
      "Epoch 22: Processed 150 batches...\n",
      "Epoch 22: Processed 200 batches...\n",
      "Epoch 22: Processed 250 batches...\n",
      "Epoch 22: Processed 300 batches...\n",
      "Epoch 22: Processed 350 batches...\n",
      "Epoch 22: Processed 400 batches...\n",
      "Epoch 22: Processed 450 batches...\n",
      "Epoch 22: Processed 500 batches...\n",
      "Epoch 22: Processed 550 batches...\n",
      "Epoch 22: Processed 600 batches...\n",
      "Epoch 22: Processed 650 batches...\n",
      "Epoch 22: Processed 700 batches...\n",
      "Epoch 22: Processed 750 batches...\n",
      "Epoch 22: Processed 800 batches...\n",
      "Epoch 22: Processed 850 batches...\n",
      "Epoch 22: Processed 900 batches...\n",
      "Epoch 22: Processed 950 batches...\n",
      "Epoch 22: Processed 1000 batches...\n",
      "Epoch 22: Processed 1050 batches...\n",
      "Epoch 22: Processed 1100 batches...\n",
      "Epoch 22: Processed 1150 batches...\n",
      "Epoch 22: Processed 1200 batches...\n",
      "Epoch 22: Processed 1250 batches...\n",
      "Epoch 22: Processed 1300 batches...\n",
      "Epoch 22: Processed 1350 batches...\n",
      "Epoch 22: Processed 1400 batches...\n",
      "Epoch 22: Processed 1450 batches...\n",
      "Epoch 22: Processed 1500 batches...\n",
      "Epoch 22: Processed 1550 batches...\n",
      "Epoch 22: Processed 1600 batches...\n",
      "Epoch 22: Processed 1650 batches...\n",
      "Epoch 22: Processed 1700 batches...\n",
      "Epoch 22: Processed 1750 batches...\n",
      "Epoch 22: Processed 1800 batches...\n",
      "Epoch 22: Processed 1850 batches...\n",
      "Epoch 22: Processed 1900 batches...\n",
      "Epoch 22: Processed 1950 batches...\n",
      "Epoch 22: Processed 2000 batches...\n",
      "Epoch 22: Processed 2050 batches...\n",
      "Epoch 22: Processed 2100 batches...\n",
      "Epoch 22: Processed 2150 batches...\n",
      "Epoch 22: Processed 2200 batches...\n",
      "Epoch 22: Processed 2250 batches...\n",
      "Epoch 22: Processed 2300 batches...\n",
      "Epoch [22/30], Loss: 2052.1738, Train Acc: 75.44%, Val Acc: 58.12%\n",
      "Epoch 23: Processed 50 batches...\n",
      "Epoch 23: Processed 100 batches...\n",
      "Epoch 23: Processed 150 batches...\n",
      "Epoch 23: Processed 200 batches...\n",
      "Epoch 23: Processed 250 batches...\n",
      "Epoch 23: Processed 300 batches...\n",
      "Epoch 23: Processed 350 batches...\n",
      "Epoch 23: Processed 400 batches...\n",
      "Epoch 23: Processed 450 batches...\n",
      "Epoch 23: Processed 500 batches...\n",
      "Epoch 23: Processed 550 batches...\n",
      "Epoch 23: Processed 600 batches...\n",
      "Epoch 23: Processed 650 batches...\n",
      "Epoch 23: Processed 700 batches...\n",
      "Epoch 23: Processed 750 batches...\n",
      "Epoch 23: Processed 800 batches...\n",
      "Epoch 23: Processed 850 batches...\n",
      "Epoch 23: Processed 900 batches...\n",
      "Epoch 23: Processed 950 batches...\n",
      "Epoch 23: Processed 1000 batches...\n",
      "Epoch 23: Processed 1050 batches...\n",
      "Epoch 23: Processed 1100 batches...\n",
      "Epoch 23: Processed 1150 batches...\n",
      "Epoch 23: Processed 1200 batches...\n",
      "Epoch 23: Processed 1250 batches...\n",
      "Epoch 23: Processed 1300 batches...\n",
      "Epoch 23: Processed 1350 batches...\n",
      "Epoch 23: Processed 1400 batches...\n",
      "Epoch 23: Processed 1450 batches...\n",
      "Epoch 23: Processed 1500 batches...\n",
      "Epoch 23: Processed 1550 batches...\n",
      "Epoch 23: Processed 1600 batches...\n",
      "Epoch 23: Processed 1650 batches...\n",
      "Epoch 23: Processed 1700 batches...\n",
      "Epoch 23: Processed 1750 batches...\n",
      "Epoch 23: Processed 1800 batches...\n",
      "Epoch 23: Processed 1850 batches...\n",
      "Epoch 23: Processed 1900 batches...\n",
      "Epoch 23: Processed 1950 batches...\n",
      "Epoch 23: Processed 2000 batches...\n",
      "Epoch 23: Processed 2050 batches...\n",
      "Epoch 23: Processed 2100 batches...\n",
      "Epoch 23: Processed 2150 batches...\n",
      "Epoch 23: Processed 2200 batches...\n",
      "Epoch 23: Processed 2250 batches...\n",
      "Epoch 23: Processed 2300 batches...\n",
      "Epoch [23/30], Loss: 2034.1114, Train Acc: 75.96%, Val Acc: 59.12%\n",
      "Epoch 24: Processed 50 batches...\n",
      "Epoch 24: Processed 100 batches...\n",
      "Epoch 24: Processed 150 batches...\n",
      "Epoch 24: Processed 200 batches...\n",
      "Epoch 24: Processed 250 batches...\n",
      "Epoch 24: Processed 300 batches...\n",
      "Epoch 24: Processed 350 batches...\n",
      "Epoch 24: Processed 400 batches...\n",
      "Epoch 24: Processed 450 batches...\n",
      "Epoch 24: Processed 500 batches...\n",
      "Epoch 24: Processed 550 batches...\n",
      "Epoch 24: Processed 600 batches...\n",
      "Epoch 24: Processed 650 batches...\n",
      "Epoch 24: Processed 700 batches...\n",
      "Epoch 24: Processed 750 batches...\n",
      "Epoch 24: Processed 800 batches...\n",
      "Epoch 24: Processed 850 batches...\n",
      "Epoch 24: Processed 900 batches...\n",
      "Epoch 24: Processed 950 batches...\n",
      "Epoch 24: Processed 1000 batches...\n",
      "Epoch 24: Processed 1050 batches...\n",
      "Epoch 24: Processed 1100 batches...\n",
      "Epoch 24: Processed 1150 batches...\n",
      "Epoch 24: Processed 1200 batches...\n",
      "Epoch 24: Processed 1250 batches...\n",
      "Epoch 24: Processed 1300 batches...\n",
      "Epoch 24: Processed 1350 batches...\n",
      "Epoch 24: Processed 1400 batches...\n",
      "Epoch 24: Processed 1450 batches...\n",
      "Epoch 24: Processed 1500 batches...\n",
      "Epoch 24: Processed 1550 batches...\n",
      "Epoch 24: Processed 1600 batches...\n",
      "Epoch 24: Processed 1650 batches...\n",
      "Epoch 24: Processed 1700 batches...\n",
      "Epoch 24: Processed 1750 batches...\n",
      "Epoch 24: Processed 1800 batches...\n",
      "Epoch 24: Processed 1850 batches...\n",
      "Epoch 24: Processed 1900 batches...\n",
      "Epoch 24: Processed 1950 batches...\n",
      "Epoch 24: Processed 2000 batches...\n",
      "Epoch 24: Processed 2050 batches...\n",
      "Epoch 24: Processed 2100 batches...\n",
      "Epoch 24: Processed 2150 batches...\n",
      "Epoch 24: Processed 2200 batches...\n",
      "Epoch 24: Processed 2250 batches...\n",
      "Epoch 24: Processed 2300 batches...\n",
      "Epoch [24/30], Loss: 2042.0661, Train Acc: 75.59%, Val Acc: 59.12%\n",
      "Epoch 25: Processed 50 batches...\n",
      "Epoch 25: Processed 100 batches...\n",
      "Epoch 25: Processed 150 batches...\n",
      "Epoch 25: Processed 200 batches...\n",
      "Epoch 25: Processed 250 batches...\n",
      "Epoch 25: Processed 300 batches...\n",
      "Epoch 25: Processed 350 batches...\n",
      "Epoch 25: Processed 400 batches...\n",
      "Epoch 25: Processed 450 batches...\n",
      "Epoch 25: Processed 500 batches...\n",
      "Epoch 25: Processed 550 batches...\n",
      "Epoch 25: Processed 600 batches...\n",
      "Epoch 25: Processed 650 batches...\n",
      "Epoch 25: Processed 700 batches...\n",
      "Epoch 25: Processed 750 batches...\n",
      "Epoch 25: Processed 800 batches...\n",
      "Epoch 25: Processed 850 batches...\n",
      "Epoch 25: Processed 900 batches...\n",
      "Epoch 25: Processed 950 batches...\n",
      "Epoch 25: Processed 1000 batches...\n",
      "Epoch 25: Processed 1050 batches...\n",
      "Epoch 25: Processed 1100 batches...\n",
      "Epoch 25: Processed 1150 batches...\n",
      "Epoch 25: Processed 1200 batches...\n",
      "Epoch 25: Processed 1250 batches...\n",
      "Epoch 25: Processed 1300 batches...\n",
      "Epoch 25: Processed 1350 batches...\n",
      "Epoch 25: Processed 1400 batches...\n",
      "Epoch 25: Processed 1450 batches...\n",
      "Epoch 25: Processed 1500 batches...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to Filter Corrupt Images\n",
    "def filter_corrupt_images(dataset):\n",
    "    valid_samples = []\n",
    "    for path, label in dataset.samples:\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            valid_samples.append((path, label))\n",
    "        except Exception as e:\n",
    "            print(f\"Corrupt image removed: {path} - {e}\")\n",
    "    dataset.samples = valid_samples\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\") if isinstance(img, Image.Image) else img),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.85, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.RandomErasing(p=0.3),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "train_data_path = \"/content/affectnet/AffectNet/train\"\n",
    "val_data_path = \"/content/affectnet/AffectNet/val\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_data_path, transform=transform)\n",
    "\n",
    "# Filter Out Corrupt Images\n",
    "filter_corrupt_images(train_dataset)\n",
    "filter_corrupt_images(val_dataset)\n",
    "\n",
    "# Compute Class Weights\n",
    "class_counts = Counter(train_dataset.targets)\n",
    "num_samples = sum(class_counts.values())\n",
    "weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Load Data\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Load ConvNeXt-Large Model\n",
    "model = models.convnext_large(weights=models.ConvNeXt_Large_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify Classifier for 8 Classes\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.LayerNorm(model.classifier[2].in_features),\n",
    "    nn.Dropout(0.6),  # Increased dropout for regularization\n",
    "    nn.Linear(model.classifier[2].in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 8)\n",
    ")\n",
    "\n",
    "# Load Checkpoint (Resume from Epoch 22)\n",
    "checkpoint_path = \"/content/affectnet_convnext_large_epoch20.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# Remove \"_orig_mod.\" keys if necessary\n",
    "new_checkpoint = {key.replace(\"_orig_mod.\", \"\"): val for key, val in checkpoint.items()}\n",
    "\n",
    "# Load Weights\n",
    "model.load_state_dict(new_checkpoint, strict=False)\n",
    "\n",
    "print(\"Checkpoint successfully loaded! Resuming training from Epoch 22.\")\n",
    "\n",
    "# Move Model to Device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Loss, Optimizer & Scheduler\n",
    "criterion = nn.CrossEntropyLoss(weight=weights, label_smoothing=0.05)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-6, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "# Mixed Precision Training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Early Stopping Parameters\n",
    "best_val_acc = 0.0\n",
    "epochs_without_improvement = 0\n",
    "early_stopping_patience = 3\n",
    "\n",
    "# Resume Training from Epoch 22\n",
    "print(\"\\nContinuing Fine-tuning from Epoch 22...\\n\")\n",
    "\n",
    "for epoch in range(22, 31):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    running_loss, correct_train, total_train = 0.0, 0, 0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    batch_count = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        try:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping corrupt batch: {e}\")\n",
    "            continue\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Prevent exploding gradients\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "        batch_count += 1\n",
    "        if batch_count % 50 == 0:\n",
    "            print(f\"Epoch {epoch}: Processed {batch_count} batches...\")\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    scheduler.step(train_accuracy)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    correct_val, total_val = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            try:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping corrupt batch in validation: {e}\")\n",
    "                continue\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "    print(f\"Epoch [{epoch}/30], Loss: {running_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"affectnet_convnext_large_epoch{epoch}.pt\")\n",
    "        print(f\"Model saved: affectnet_convnext_large_epoch{epoch}.pt\")\n",
    "\n",
    "    # Early Stopping Condition\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= early_stopping_patience:\n",
    "        print(f\"Early stopping triggered. Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "        break\n",
    "\n",
    "# Save Final Model\n",
    "torch.save(model.state_dict(), \"affectnet_convnext_large_final.pt\")\n",
    "print(\"\\nTraining complete! Final model saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
